{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des librairies\n",
    "- pixiedust (Kernel Python/Scala)\n",
    "- time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pixiedust\n",
    "import time\n",
    "import os\n",
    "import tweepy\n",
    "import json\n",
    "import json_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration du nom du fichier utilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TIME=1521105739.7455528\n",
      "env: OUTPUT_TWEET_TXT_FILENAME=output_tweet_1521105739.7455528.txt\n",
      "env: TWEET_JSON_FILENAME=input_tweet_1521105739.7455528.json\n"
     ]
    }
   ],
   "source": [
    "%env TIME={time.time()}\n",
    "\n",
    "%env OUTPUT_TWEET_TXT_FILENAME=output_tweet_{os.environ['TIME']}.txt\n",
    "%env TWEET_JSON_FILENAME=input_tweet_{os.environ['TIME']}.json\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Collect des données twitter et stockage dans un json 'tweets_time.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Variables that contains the user credentials to access Twitter API\n",
    "API_key = json.load(open(\"API_key.txt\", \"r\"))\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_key[\"consumer_key\"], API_key[\"consumer_secret\"])\n",
    "auth.set_access_token(API_key[\"access_token\"], API_key[\"access_token_secret\"])\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "keyword = \"#Trump\"\n",
    "tweets = tweepy.Cursor(api.search, q=keyword).items(10)\n",
    "json_tweets = [json.dumps(tweet._json) for tweet in tweets]\n",
    "json_str = \"\\n\\r\".join(json_tweets)\n",
    "\n",
    "filename = \"tweets-database/\"+os.environ['TWEET_JSON_FILENAME']\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd Algo1\n",
    "cp trump.json ../tweets-database/$TWEET_JSON_FILENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise à jour de l'algorithme sur le Datacenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from plugins.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading project definition from /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/project\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from build.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mSet current project to SparkSenti (in build file:/Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mExclude scala-library-2.11.8.jar from the package\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mPackaging /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/scala-2.11/sparksenti_2.11-0.1.jar ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mDone packaging.\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] Creating a distributable package in /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/pack\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] Copying libraries to /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/pack/lib\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] project jars:\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m/Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/scala-2.11/sparksenti_2.11-0.1.jar\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] project dependencies:\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0morg.scala-lang:scala-reflect:2.11.8\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mxalan:xalan:2.7.0\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.typesafe.play:play-functional_2.11:2.6.7\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mjoda-time:joda-time:2.9.9\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mxml-apis:xml-apis:1.3.03\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.fasterxml.jackson.datatype:jackson-datatype-jsr310:2.8.9\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.fasterxml.jackson.core:jackson-core:2.8.9\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mde.jollyday:jollyday:0.4.7\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0medu.stanford.nlp:stanford-corenlp:3.3.0-models\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0medu.stanford.nlp:stanford-corenlp:3.3.0\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.fasterxml.jackson.datatype:jackson-datatype-jdk8:2.8.9\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.typesafe.play:play-json_2.11:2.6.7\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.fasterxml.jackson.core:jackson-annotations:2.8.9\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mxerces:xercesImpl:2.8.0\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0morg.typelevel:macro-compat_2.11:1.1.1\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.fasterxml.jackson.core:jackson-databind:2.8.9\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.googlecode.efficient-java-matrix-library:ejml:0.23\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0morg.scalaz:scalaz-core_2.11:7.2.18\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mcom.io7m.xom:xom:1.2.10\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mjavax.xml.bind:jaxb-api:2.2.7\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] unmanaged dependencies:\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] explicit dependencies:\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] Create a bin folder: /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/pack/bin\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] Generating launch scripts\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] main class for test: algo1_worksheet.test\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] Generating /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/pack/bin/test\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] Generating /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/pack/bin/test.bat\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] packed resource directories = /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/src/pack\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] Generating /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/pack/Makefile\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] Generating /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/target/pack/VERSION\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0m[SparkSenti] done.\u001b[0m\n",
      "spawn scp target/scala-2.11/sparksenti_2.11-0.1.jar durivault1@156.18.90.100:./SparkSenti-0.1/lib\r\n",
      "durivault1@156.18.90.100's password: \r\n",
      "\r",
      "sparksenti_2.11-0.1.jar                         0%    0     0.0KB/s   --:-- ETA\r",
      "sparksenti_2.11-0.1.jar                       100%   33KB   3.6MB/s   00:00    \r\n",
      "\u001b[0m[\u001b[0m\u001b[32msuccess\u001b[0m] \u001b[0m\u001b[0mTotal time: 6 s, completed Mar 15, 2018 10:22:38 AM\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd Algo1\n",
    "sbt \"push\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Envoie des tweets collectés sur le datacenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from plugins.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading project definition from /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/project\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from build.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mSet current project to SparkSenti (in build file:/Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/)\u001b[0m\n",
      "spawn scp input_tweet_1521105739.7455528.json durivault1@156.18.90.100:.\r\n",
      "durivault1@156.18.90.100's password: \r\n",
      "\r",
      "input_tweet_1521105739.7455528.json             0%    0     0.0KB/s   --:-- ETA\r",
      "input_tweet_1521105739.7455528.json           100%  577KB   7.0MB/s   00:00    \r\n",
      "spawn ssh durivault1@156.18.90.100\r\n",
      "durivault1@156.18.90.100's password: \r\n",
      "Last login: Thu Mar 15 09:39:59 2018 from us0552.wifi.ec-lyon.fr\r",
      "\r\n",
      "Welcome to Bright release         7.3\r\n",
      "\r\n",
      "                                                        Based on CentOS Linux 7\r\n",
      "                                                                    ID: #000002\r\n",
      "\r\n",
      "Use the following commands to adjust your environment:\r\n",
      "\r\n",
      "'module avail'            - show available modules\r\n",
      "'module add <module>'     - adds a module to your environment for this session\r\n",
      "'module initadd <module>' - configure module to be loaded at every login\r\n",
      "\r\n",
      "-------------------------------------------------------------------------------\r\n",
      "\u001b]0;durivault1@bright73:~\u0007[durivault1@bright73 ~]$ hdfs dfs -put input_tweet_1521105739.7455528.json\r\n",
      "\u001b]0;durivault1@bright73:~\u0007[durivault1@bright73 ~]$ \n",
      "\u001b[0m[\u001b[0m\u001b[32msuccess\u001b[0m] \u001b[0m\u001b[0mTotal time: 3 s, completed Mar 15, 2018 10:22:58 AM\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cp tweets-database/$TWEET_JSON_FILENAME Algo1/$TWEET_JSON_FILENAME\n",
    "cd Algo1\n",
    "sbt \"put $TWEET_JSON_FILENAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution de l'analyse de sentiments des tweets colléctés sur le datacenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd Algo1\n",
    "rm -rf $TWEET_JSON_FILENAME\n",
    "sbt \"submit $TWEET_JSON_FILENAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération du resultat de l'analyse : fichier text (id_tweet sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from plugins.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading project definition from /Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/project\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from build.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mSet current project to SparkSenti (in build file:/Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0mjava.io.FileNotFoundException: server.conf (No such file or directory)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat java.io.FileInputStream.open(Native Method)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat java.io.FileInputStream.<init>(FileInputStream.java:138)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat scala.io.Source$.fromFile(Source.scala:91)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat scala.io.Source$.fromFile(Source.scala:76)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat scala.io.Source$.fromFile(Source.scala:54)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat $e0d6e860966a7a8c1d4c$.getCredentials(build.sbt:33)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat $fe7d0f3756d3a4a2351f$.$anonfun$$sbtdef$3(/Users/Augustin/Documents/Cours/Centrale/Cours/S10/SparkSenti/SparkSenti/Algo1/build.sbt:67)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat $fe7d0f3756d3a4a2351f$$$Lambda$2397/407567224.apply$mcV$sp(Unknown Source)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.std.Transform$$anon$3.$anonfun$apply$2(System.scala:44)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.std.Transform$$anon$3$$Lambda$1815/2136347897.apply(Unknown Source)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.std.Transform$$anon$4.work(System.scala:64)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.Execute.$anonfun$submit$2(Execute.scala:257)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.Execute$$Lambda$1825/210079133.apply(Unknown Source)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.Execute.work(Execute.scala:266)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.Execute.$anonfun$submit$1(Execute.scala:257)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.Execute$$Lambda$1817/286169474.apply(Unknown Source)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:167)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.ConcurrentRestrictions$$anon$4$$Lambda$1824/327574313.apply(Unknown Source)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat sbt.CompletionService$$anon$2.call(CompletionService.scala:32)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m\tat java.lang.Thread.run(Thread.java:745)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0m(*:\u001b[31mgetOutput\u001b[0m) java.io.FileNotFoundException: server.conf (No such file or directory)\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[31merror\u001b[0m] \u001b[0m\u001b[0mTotal time: 0 s, completed Mar 15, 2018 10:19:12 AM\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cp: defaultoutput.txt: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd Algo1\n",
    "sbt \"getOutput 'defaultoutput.txt'\"\n",
    "cp defaultoutput.txt ../tweets-database/$OUTPUT_TWEET_TXT_FILENAME\n",
    "rm -rf defaultoutput.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour test de viz (evite de lancer le workflow complet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%env OUTPUT_TWEET_TXT_FILENAME=output_test.txt\n",
    "%env TWEET_JSON_FILENAME=input_test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping des données pour Viz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_output=open(\"tweets-database/\"+os.environ['OUTPUT_TWEET_TXT_FILENAME'],\"r\", encoding=\"utf8\");\n",
    "file_tweet=open(\"tweets-database/\"+os.environ['TWEET_JSON_FILENAME'],\"r\", encoding=\"utf8\");\n",
    "\n",
    "\n",
    "def parserByTweet(file_output,file_tweet):\n",
    "    fileText = file_output.read().replace(\"Négatif\",\"Negatif\")\n",
    "    fileTweets = fileText.split(\"\\n\\n\")[1:]\n",
    "    \n",
    "    tweetList = []\n",
    "    \n",
    "    \n",
    "    for tweet in fileTweets[:-1]:\n",
    "        data=tweet.split(\"\\n\")\n",
    "        tweet_text = data[0][7:]\n",
    "        result = data[1][7:]\n",
    "        tweet_id = data[2][9:]\n",
    "        for tweet_json in json_lines.reader(file_tweet):\n",
    "            if int(tweet_id)==int(tweet_json[\"id\"]):\n",
    "                new={}\n",
    "                new[\"result\"]=result\n",
    "                new[\"tweet\"]=tweet_json\n",
    "                tweetList.append(new)  \n",
    "    \n",
    "\n",
    "\n",
    "    return(tweetList)\n",
    "    \n",
    "data_to_viz=parserByTweet(file_output,file_tweet)\n",
    "print(data_to_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.2)",
   "language": "python",
   "name": "pythonwithpixiedustspark22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
