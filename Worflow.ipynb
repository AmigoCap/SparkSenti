{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des librairies\n",
    "- pixiedust (Kernel Python/Scala)\n",
    "- time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pixiedust\n",
    "import time\n",
    "import os\n",
    "import tweepy\n",
    "import json\n",
    "import json_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration du nom du fichier utilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TIME=1521642018.6679099\n",
      "env: OUTPUT_TWEET_FILENAME=output_tweet_1521642018.6679099.json\n",
      "env: TWEET_JSON_FILENAME=input_tweet_1521642018.6679099.json\n"
     ]
    }
   ],
   "source": [
    "%env TIME={time.time()}\n",
    "%env OUTPUT_TWEET_FILENAME=output_tweet_{os.environ['TIME']}.json\n",
    "%env TWEET_JSON_FILENAME=input_tweet_{os.environ['TIME']}.json\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Collect des données twitter et stockage dans un json 'tweets_time.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_geo=False\n",
    "API_key = json.load(open(\"API_key.txt\", \"r\"))\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_key[\"consumer_key\"], API_key[\"consumer_secret\"])\n",
    "auth.set_access_token(API_key[\"access_token\"], API_key[\"access_token_secret\"])\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "keyword = \"bitcoin\"\n",
    "\n",
    "tweets = api.search( q=keyword,tweet_mode='extended',include_rts=False,count=2000)\n",
    "\n",
    "json_tweets=[]\n",
    "for tweet in tweets:\n",
    "    json_tweets.append(json.dumps(tweet._json))\n",
    "\n",
    "json_str = \"\\n\".join(json_tweets)\n",
    "\n",
    "filename = \"tweets-database/\"+os.environ['TWEET_JSON_FILENAME']\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Envoie des tweets collectés sur le datacenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from idea.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading global plugins from /Users/Frego/.sbt/1.0/plugins\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from plugins.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading project definition from /Users/Frego/Documents/Centrale/4A/OPTION/08_Projet/SparkSenti/Algo1/project\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from build.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mSet current project to SparkSenti (in build file:/Users/Frego/Documents/Centrale/4A/OPTION/08_Projet/SparkSenti/Algo1/)\u001b[0m\n",
      "spawn scp input_tweet_1521642018.6679099.json fregosi1@sparksenti:.\r\n",
      "fregosi1@sparksenti's password: \r\n",
      "\r",
      "input_tweet_1521642018.6679099.json             0%    0     0.0KB/s   --:-- ETA\r",
      "input_tweet_1521642018.6679099.json           100%  483KB   7.7MB/s   00:00    \r\n",
      "spawn ssh fregosi1@sparksenti\r\n",
      "fregosi1@sparksenti's password: \r\n",
      "Last login: Wed Mar 21 14:49:30 2018 from wfgw.wifietud.ec-lyon.fr\r",
      "\r\n",
      "Welcome to Bright release         7.3\r\n",
      "\r\n",
      "                                                        Based on CentOS Linux 7\r\n",
      "                                                                    ID: #000002\r\n",
      "\r\n",
      "Use the following commands to adjust your environment:\r\n",
      "\r\n",
      "'module avail'            - show available modules\r\n",
      "'module add <module>'     - adds a module to your environment for this session\r\n",
      "'module initadd <module>' - configure module to be loaded at every login\r\n",
      "\r\n",
      "-------------------------------------------------------------------------------\r\n",
      "\u001b]0;fregosi1@bright73:~\u0007[fregosi1@bright73 ~]$ hdfs dfs -put input_tweet_1521642018.6679099.json\r\n",
      "\u001b]0;fregosi1@bright73:~\u0007[fregosi1@bright73 ~]$ \n",
      "\u001b[0m[\u001b[0m\u001b[32msuccess\u001b[0m] \u001b[0m\u001b[0mTotal time: 4 s, completed 21 mars 2018 15:20:56\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cp tweets-database/$TWEET_JSON_FILENAME Algo1/$TWEET_JSON_FILENAME\n",
    "cd Algo1\n",
    "sbt \"put $TWEET_JSON_FILENAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution de l'analyse de sentiments des tweets colléctés sur le datacenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from idea.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading global plugins from /Users/Frego/.sbt/1.0/plugins\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from plugins.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading project definition from /Users/Frego/Documents/Centrale/4A/OPTION/08_Projet/SparkSenti/Algo1/project\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from build.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mSet current project to SparkSenti (in build file:/Users/Frego/Documents/Centrale/4A/OPTION/08_Projet/SparkSenti/Algo1/)\u001b[0m\n",
      "spawn ssh fregosi1@sparksenti\r\n",
      "fregosi1@sparksenti's password: \r\n",
      "Last login: Wed Mar 21 15:20:53 2018 from wfgw.wifietud.ec-lyon.fr\r",
      "\r\n",
      "Welcome to Bright release         7.3\r\n",
      "\r\n",
      "                                                        Based on CentOS Linux 7\r\n",
      "                                                                    ID: #000002\r\n",
      "\r\n",
      "Use the following commands to adjust your environment:\r\n",
      "\r\n",
      "'module avail'            - show available modules\r\n",
      "'module add <module>'     - adds a module to your environment for this session\r\n",
      "'module initadd <module>' - configure module to be loaded at every login\r\n",
      "\r\n",
      "-------------------------------------------------------------------------------\r\n",
      "\u001b]0;fregosi1@bright73:~\u0007[fregosi1@bright73 ~]$ echo SparkSenti-0.1/lib/*.jar | tr \" \" \",\"\r\n",
      "SparkSenti-0.1/lib/akka-actor_2.11-2.5.4.jar,SparkSenti-0.1/lib/akka-slf4j_2.11-2.5.4.jar,SparkSenti-0.1/lib/antlr4-runtime-4.6.jar,SparkSenti-0.1/lib/args4j-2.0.23.jar,SparkSenti-0.1/lib/async-http-client-1.7.16.jar,SparkSenti-0.1/lib/bioresources-1.1.24.jar,SparkSenti-0.1/lib/clearnlp-2.0.2.jar,SparkSenti-0.1/lib/common_2.11-0.0.7.jar,SparkSenti-0.1/lib/common-scala_2.10-1.1.2.jar,SparkSenti-0.1/lib/commons-codec-1.4.jar,SparkSenti-0.1/lib/commons-io-2.5.jar,SparkSenti-0.1/lib/commons-lang3-3.4.jar,SparkSenti-0.1/lib/config-1.3.1.jar,SparkSenti-0.1/lib/dispatch-core_2.10-0.11.0.jar,SparkSenti-0.1/lib/ejml-0.23.jar,SparkSenti-0.1/lib/guava-14.0.1.jar,SparkSenti-0.1/lib/hppc-0.5.2.jar,SparkSenti-0.1/lib/jackson-annotations-2.8.9.jar,SparkSenti-0.1/lib/jackson-core-2.8.9.jar,SparkSenti-0.1/lib/jackson-databind-2.8.9.jar,SparkSenti-0.1/lib/jackson-datatype-jdk8-2.8.9.jar,SparkSenti-0.1/lib/jackson-datatype-jsr310-2.8.9.jar,SparkSenti-0.1/lib/javax.json-api-1.0.jar,SparkSenti-0.1/lib/javax.servlet-2.5.0.v201103041518.jar,SparkSenti-0.1/lib/jaxb-api-2.2.7.jar,SparkSenti-0.1/lib/jetty-continuation-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-http-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-io-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-security-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-server-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-servlet-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-util-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-webapp-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-xml-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jline-2.12.1.jar,SparkSenti-0.1/lib/joda-time-2.9.9.jar,SparkSenti-0.1/lib/jollyday-0.4.7.jar,SparkSenti-0.1/lib/jregex-1.2_01.jar,SparkSenti-0.1/lib/json4s-ast_2.11-3.5.2.jar,SparkSenti-0.1/lib/json4s-core_2.11-3.5.2.jar,SparkSenti-0.1/lib/json4s-jackson_2.11-3.5.2.jar,SparkSenti-0.1/lib/json4s-scalap_2.11-3.5.2.jar,SparkSenti-0.1/lib/liblinear-1.94.jar,SparkSenti-0.1/lib/libsvm-3.17.jar,SparkSenti-0.1/lib/log4j-1.2.17.jar,SparkSenti-0.1/lib/logback-classic-1.0.10.jar,SparkSenti-0.1/lib/logback-core-1.0.10.jar,SparkSenti-0.1/lib/macro-compat_2.11-1.1.1.jar,SparkSenti-0.1/lib/maltparser-1.9.0.jar,SparkSenti-0.1/lib/morpha-stemmer-1.0.5.jar,SparkSenti-0.1/lib/netty-3.6.3.Final.jar,SparkSenti-0.1/lib/nlptools-core_2.10-2.4.5.jar,SparkSenti-0.1/lib/nlptools-stem-morpha_2.10-2.4.5.jar,SparkSenti-0.1/lib/paranamer-2.8.jar,SparkSenti-0.1/lib/play-functional_2.11-2.6.7.jar,SparkSenti-0.1/lib/play-json_2.11-2.6.7.jar,SparkSenti-0.1/lib/processors-corenlp_2.11-6.1.3.jar,SparkSenti-0.1/lib/processors-main_2.11-6.1.3.jar,SparkSenti-0.1/lib/processors-modelscorenlp_2.11-6.1.3.jar,SparkSenti-0.1/lib/processors-modelsmain_2.11-6.1.3.jar,SparkSenti-0.1/lib/processors-odin_2.11-6.1.3.jar,SparkSenti-0.1/lib/scala-java8-compat_2.11-0.7.0.jar,SparkSenti-0.1/lib/scala-logging_2.11-3.4.0.jar,SparkSenti-0.1/lib/scala-parser-combinators_2.11-1.0.3.jar,SparkSenti-0.1/lib/scala-reflect-2.11.8.jar,SparkSenti-0.1/lib/scala-xml_2.11-1.0.6.jar,SparkSenti-0.1/lib/scalaz-core_2.11-7.2.18.jar,SparkSenti-0.1/lib/scopt_2.10-2.1.0.jar,SparkSenti-0.1/lib/slf4j-api-1.7.10.jar,SparkSenti-0.1/lib/snakeyaml-1.14.jar,SparkSenti-0.1/lib/spark-corenlp-0.2.0-s_2.11.jar,SparkSenti-0.1/lib/sparksenti_2.11-0.1.jar,SparkSenti-0.1/lib/spark-sql_2.10-1.0.0.jar,SparkSenti-0.1/lib/stanford-corenlp-3.3.0.jar,SparkSenti-0.1/lib/stanford-corenlp-3.3.0-models.jar,SparkSenti-0.1/lib/stanford-corenlp-3.5.1.jar,SparkSenti-0.1/lib/stanford-corenlp-3.5.1-models.jar,SparkSenti-0.1/lib/stanford-parser-3.4.jar,SparkSenti-0.1/lib/unfiltered_2.10-0.7.0.jar,SparkSenti-0.1/lib/unfiltered-filter_2.10-0.7.0.jar,SparkSenti-0.1/lib/unfiltered-jetty_2.10-0.7.0.jar,SparkSenti-0.1/lib/unfiltered-util_2.10-0.7.0.jar,SparkSenti-0.1/lib/xalan-2.7.0.jar,SparkSenti-0.1/lib/xercesImpl-2.8.0.jar,SparkSenti-0.1/lib/xml-apis-1.3.03.jar,SparkSenti-0.1/lib/xom-1.2.10.jar\r\n",
      "\u001b]0;fregosi1@bright73:~\u0007[fregosi1@bright73 ~]$ spark-submit --master yarn --conf spark.executorEnv.JAVA_ \r",
      "HOME=/usr/lib/jvm/jre-1.8.0-openjdk/ --class algo1_worksheet.test --jars SparkSe \r",
      "nti-0.1/lib/akka-actor_2.11-2.5.4.jar,SparkSenti-0.1/lib/akka-slf4j_2.11-2.5.4.j \r",
      "ar,SparkSenti-0.1/lib/antlr4-runtime-4.6.jar,SparkSenti-0.1/lib/args4j-2.0.23.ja \r",
      "r,SparkSenti-0.1/lib/async-http-client-1.7.16.jar,SparkSenti-0.1/lib/bioresource \r",
      "s-1.1.24.jar,SparkSenti-0.1/lib/clearnlp-2.0.2.jar,SparkSenti-0.1/lib/common_2.1 \r",
      "1-0.0.7.jar,SparkSenti-0.1/lib/common-scala_2.10-1.1.2.jar,SparkSenti-0.1/lib/co \r",
      "mmons-codec-1.4.jar,SparkSenti-0.1/lib/commons-io-2.5.jar,SparkSenti-0.1/lib/com \r",
      "mons-lang3-3.4.jar,SparkSenti-0.1/lib/config-1.3.1.jar,SparkSenti-0.1/lib/dispat \r",
      "ch-core_2.10-0.11.0.jar,SparkSenti-0.1/lib/ejml-0.23.jar,SparkSenti-0.1/lib/guav \r",
      "a-14.0.1.jar,SparkSenti-0.1/lib/hppc-0.5.2.jar,SparkSenti-0.1/lib/jackson-annota \r",
      "tions-2.8.9.jar,SparkSenti-0.1/lib/jackson-core-2.8.9.jar,SparkSenti-0.1/lib/jac \r",
      "kson-databind-2.8.9.jar,SparkSenti-0.1/lib/jackson-datatype-jdk8-2.8.9.jar,Spark \r",
      "Senti-0.1/lib/jackson-datatype-jsr310-2.8.9.jar,SparkSenti-0.1/lib/javax.json-ap \r",
      "i-1.0.jar,SparkSenti-0.1/lib/javax.servlet-2.5.0.v201103041518.jar,SparkSenti-0. \r",
      "1/lib/jaxb-api-2.2.7.jar,SparkSenti-0.1/lib/jetty-continuation-7.6.9.v20130131.j \r",
      "ar,SparkSenti-0.1/lib/jetty-http-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-io \r",
      "-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-security-7.6.9.v20130131.jar,Spark \r",
      "Senti-0.1/lib/jetty-server-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-servlet- \r",
      "7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-util-7.6.9.v20130131.jar,SparkSenti \r",
      "-0.1/lib/jetty-webapp-7.6.9.v20130131.jar,SparkSenti-0.1/lib/jetty-xml-7.6.9.v20 \r",
      "130131.jar,SparkSenti-0.1/lib/jline-2.12.1.jar,SparkSenti-0.1/lib/joda-time-2.9. \r",
      "9.jar,SparkSenti-0.1/lib/jollyday-0.4.7.jar,SparkSenti-0.1/lib/jregex-1.2_01.jar \r",
      ",SparkSenti-0.1/lib/json4s-ast_2.11-3.5.2.jar,SparkSenti-0.1/lib/json4s-core_2.1 \r",
      "1-3.5.2.jar,SparkSenti-0.1/lib/json4s-jackson_2.11-3.5.2.jar,SparkSenti-0.1/lib/ \r",
      "json4s-scalap_2.11-3.5.2.jar,SparkSenti-0.1/lib/liblinear-1.94.jar,SparkSenti-0. \r",
      "1/lib/libsvm-3.17.jar,SparkSenti-0.1/lib/log4j-1.2.17.jar,SparkSenti-0.1/lib/log \r",
      "back-classic-1.0.10.jar,SparkSenti-0.1/lib/logback-core-1.0.10.jar,SparkSenti-0. \r",
      "1/lib/macro-compat_2.11-1.1.1.jar,SparkSenti-0.1/lib/maltparser-1.9.0.jar,SparkS \r",
      "enti-0.1/lib/morpha-stemmer-1.0.5.jar,SparkSenti-0.1/lib/netty-3.6.3.Final.jar,S \r",
      "parkSenti-0.1/lib/nlptools-core_2.10-2.4.5.jar,SparkSenti-0.1/lib/nlptools-stem- \r",
      "morpha_2.10-2.4.5.jar,SparkSenti-0.1/lib/paranamer-2.8.jar,SparkSenti-0.1/lib/pl \r",
      "ay-functional_2.11-2.6.7.jar,SparkSenti-0.1/lib/play-json_2.11-2.6.7.jar,SparkSe \r",
      "nti-0.1/lib/processors-corenlp_2.11-6.1.3.jar,SparkSenti-0.1/lib/processors-main \r",
      "_2.11-6.1.3.jar,SparkSenti-0.1/lib/processors-modelscorenlp_2.11-6.1.3.jar,Spark \r",
      "Senti-0.1/lib/processors-modelsmain_2.11-6.1.3.jar,SparkSenti-0.1/lib/processors \r",
      "-odin_2.11-6.1.3.jar,SparkSenti-0.1/lib/scala-java8-compat_2.11-0.7.0.jar,SparkS \r",
      "enti-0.1/lib/scala-logging_2.11-3.4.0.jar,SparkSenti-0.1/lib/scala-parser-combin \r",
      "ators_2.11-1.0.3.jar,SparkSenti-0.1/lib/scala-reflect-2.11.8.jar,SparkSenti-0.1/ \r",
      "lib/scala-xml_2.11-1.0.6.jar,SparkSenti-0.1/lib/scalaz-core_2.11-7.2.18.jar,Spar \r",
      "kSenti-0.1/lib/scopt_2.10-2.1.0.jar,SparkSenti-0.1/lib/slf4j-api-1.7.10.jar,Spar \r",
      "kSenti-0.1/lib/snakeyaml-1.14.jar,SparkSenti-0.1/lib/spark-corenlp-0.2.0-s_2.11. \r",
      "jar,SparkSenti-0.1/lib/sparksenti_2.11-0.1.jar,SparkSenti-0.1/lib/spark-sql_2.10 \r",
      "-1.0.0.jar,SparkSenti-0.1/lib/stanford-corenlp-3.3.0.jar,SparkSenti-0.1/lib/stan \r",
      "ford-corenlp-3.3.0-models.jar,SparkSenti-0.1/lib/stanford-corenlp-3.5.1.jar,Spar \r",
      "kSenti-0.1/lib/stanford-corenlp-3.5.1-models.jar,SparkSenti-0.1/lib/stanford-par \r",
      "ser-3.4.jar,SparkSenti-0.1/lib/unfiltered_2.10-0.7.0.jar,SparkSenti-0.1/lib/unfi \r",
      "ltered-filter_2.10-0.7.0.jar,SparkSenti-0.1/lib/unfiltered-jetty_2.10-0.7.0.jar, \r",
      "SparkSenti-0.1/lib/unfiltered-util_2.10-0.7.0.jar,SparkSenti-0.1/lib/xalan-2.7.0 \r",
      ".jar,SparkSenti-0.1/lib/xercesImpl-2.8.0.jar,SparkSenti-0.1/lib/xml-apis-1.3.03. \r",
      "jar,SparkSenti-0.1/lib/xom-1.2.10.jar SparkSenti-0.1/lib/sparksenti_2.11-0.1.jar \r",
      " input_tweet_1521642018.6679099.json > defaultoutput.json\r\n",
      "18/03/21 15:21:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n",
      "18/03/21 15:21:26 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\r\n",
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 2]\r",
      "[Stage 0:>                                                          (0 + 2) / 2]\r",
      "[Stage 0:=============================>                             (1 + 1) / 2]\r",
      "                                                                                \r",
      "\u001b]0;fregosi1@bright73:~\u0007[fregosi1@bright73 ~]$ \n",
      "\u001b[0m[\u001b[0m\u001b[32msuccess\u001b[0m] \u001b[0m\u001b[0mTotal time: 43 s, completed 21 mars 2018 15:22:05\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd Algo1\n",
    "rm -rf $TWEET_JSON_FILENAME\n",
    "sbt \"submit $TWEET_JSON_FILENAME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération du resultat de l'analyse : fichier text (id_tweet sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from idea.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading global plugins from /Users/Frego/.sbt/1.0/plugins\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from plugins.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading project definition from /Users/Frego/Documents/Centrale/4A/OPTION/08_Projet/SparkSenti/Algo1/project\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mLoading settings from build.sbt ...\u001b[0m\n",
      "\u001b[0m[\u001b[0m\u001b[0minfo\u001b[0m] \u001b[0m\u001b[0mSet current project to SparkSenti (in build file:/Users/Frego/Documents/Centrale/4A/OPTION/08_Projet/SparkSenti/Algo1/)\u001b[0m\n",
      "spawn scp fregosi1@sparksenti:'defaultoutput.json' .\r\n",
      "fregosi1@sparksenti's password: \r\n",
      "\r",
      "defaultoutput.json                              0%    0     0.0KB/s   --:-- ETA\r",
      "defaultoutput.json                            100%  487KB   3.6MB/s   00:00    \r\n",
      "\n",
      "\u001b[0m[\u001b[0m\u001b[32msuccess\u001b[0m] \u001b[0m\u001b[0mTotal time: 1 s, completed 21 mars 2018 15:22:25\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd Algo1\n",
    "sbt \"getOutput 'defaultoutput.json'\"\n",
    "cp defaultoutput.json ../tweets-database/$OUTPUT_TWEET_FILENAME\n",
    "rm -rf defaultoutput.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour test de viz (evite de lancer le workflow complet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTPUT_TWEET_FILENAME=output_test.json\n",
      "env: TWEET_JSON_FILENAME=input_test.json\n"
     ]
    }
   ],
   "source": [
    "%env OUTPUT_TWEET_FILENAME=output_test.json\n",
    "%env TWEET_JSON_FILENAME=input_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_json = open(\"tweets-database/\"+os.environ['OUTPUT_TWEET_FILENAME'],\"r\", encoding=\"utf8\");\n",
    "\n",
    "\n",
    "file_json = open(\"tweets-database/output_tweet_1521642018.6679099.json\",\"r\", encoding=\"utf8\");\n",
    "reader = json_lines.reader(file_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-707257dd3d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#for tweet in reader :      # =======> sert à afficher tout les tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeolocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/json_lines/_lib.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_iter_json_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_decode_json_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/json_lines/_lib.py\u001b[0m in \u001b[0;36m_decode_json_line\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "import random\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(timeout=3)\n",
    "\n",
    "\n",
    "\n",
    "WASH_COORD = [38.8949549, -77.0366456]\n",
    "NYC_COORD = [40.7128, -74.0059]\n",
    "LYON_COORD = [45.750000,4.850000]\n",
    "CHICAGO_COORD = [41.850033, -87.6500523]\n",
    "US_COORD = [39,-95]\n",
    "\n",
    "# Build map \n",
    "map_main = folium.Map(location=US_COORD, \n",
    "                      zoom_start=4, \n",
    "                      tiles='cartodbpositron', \n",
    "                      width=640, \n",
    "                      height=400)\n",
    "\n",
    "\n",
    "\n",
    "import itertools           #  ======> sert à limiter le nombre de tweets afficher sur la carte\n",
    "#for tweet in itertools.islice(reader, 30):\n",
    "#for tweet in reader :      # =======> sert à afficher tout les tweets\n",
    "\n",
    "for tweet in itertools.islice(reader, 10):\n",
    "    if (tweet['tweet']!= ''):\n",
    "        location = geolocator.geocode(tweet['tweet']['user']['location'])\n",
    "        popup_image ='''<img src=\"''' + tweet['tweet']['user']['profile_image_url'] + '''\" alt=\"pic \" />'''\n",
    "        popup_text = '<b>'+tweet['tweet']['user']['name']+'</b>' + ' tweeted : '+ '<i>' + tweet['tweet']['full_text'] + '</i>'\n",
    "        popup = '<center>' + popup_image + '<br\\><br\\>' + popup_text + '</center>'\n",
    "        location = [location.latitude + random.gauss(0,0000.1), location.longitude + random.gauss(0,000.1)]\n",
    "        if tweet['result'] == 'Positif':\n",
    "            folium.Marker(location,                               \n",
    "                          popup= popup,\n",
    "                          #popup= folium.Popup(test, max_width=2650),\n",
    "                          icon=folium.Icon(color='green')\n",
    "                         ).add_to(map_main)\n",
    "        elif tweet['result'] == 'Negatif':\n",
    "            folium.Marker(location,   \n",
    "                          popup= popup,\n",
    "                          icon=folium.Icon(color='red')\n",
    "                         ).add_to(map_main)            \n",
    "        elif tweet['result'] == 'Neutre':\n",
    "            folium.Marker(location,   \n",
    "                          popup= popup,\n",
    "                          icon=folium.Icon(color='lightgray')\n",
    "                         ).add_to(map_main)                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display map in Jupyter\n",
    "map_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import squarify \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y=[0,0,0];\n",
    "with open('tweets-database/output_tweet_1521640131.3454146.json', 'rb') as f:\n",
    "    for tweet in json_lines.reader(f):\n",
    "        if tweet['result'] == 'Positif':\n",
    "            y[0]+=1\n",
    "        elif tweet['result'] == 'Negatif':\n",
    "            y[1]+=1\n",
    "        elif tweet['result'] == 'Neutre':\n",
    "            y[2]+=1\n",
    "x=[\"positif\",\"negatif\",\"neutre\"];   \n",
    "squarify.plot(sizes=y, label=x, alpha=.7 ,color=[\"red\",\"green\",\"blue\"])\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.2)",
   "language": "python",
   "name": "pythonwithpixiedustspark22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
